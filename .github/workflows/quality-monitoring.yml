name: AI Discovery - Quality Monitoring

on:
  schedule:
    # Run quality checks twice daily
    - cron: '0 6,18 * * *'  # 6 AM and 6 PM UTC
  workflow_dispatch:
  push:
    branches: [main]
    paths:
      - 'content/**'
      - 'static/**'
      - 'layouts/**'

env:
  HUGO_VERSION: "0.149.0"

jobs:
  quality-check:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'
          cache: 'pip'

      - name: Install dependencies
        run: |
          pip install -r requirements.txt
          
          # Install additional quality check tools
          pip install markdownlint-cli2 html5lib beautifulsoup4
          npm install -g htmlhint stylelint

      - name: Setup Hugo
        uses: peaceiris/actions-hugo@v2
        with:
          hugo-version: ${{ env.HUGO_VERSION }}
          extended: true

      - name: Content quality analysis
        id: content-analysis
        run: |
          echo "üìä Analyzing content quality..."
          python -c "
          import os
          import re
          from pathlib import Path
          from bs4 import BeautifulSoup
          
          # Content metrics
          content_dir = Path('content')
          total_articles = 0
          total_words = 0
          avg_word_count = 0
          
          if content_dir.exists():
              for md_file in content_dir.rglob('*.md'):
                  if md_file.name != '_index.md':
                      try:
                          with open(md_file, 'r', encoding='utf-8') as f:
                              content = f.read()
                          
                          # Count words (excluding frontmatter)
                          content_body = re.split(r'^---$', content, flags=re.MULTILINE)[2] if content.count('---') >= 2 else content
                          words = len(re.findall(r'\b\w+\b', content_body))
                          
                          total_articles += 1
                          total_words += words
                      except Exception as e:
                          print(f'Error processing {md_file}: {e}')
          
          if total_articles > 0:
              avg_word_count = total_words // total_articles
          
          print(f'üìù Content Statistics:')
          print(f'   Total articles: {total_articles}')
          print(f'   Total words: {total_words}')
          print(f'   Average word count: {avg_word_count}')
          print(f'   Target word count: 2500+ words per article')
          
          # Quality thresholds
          if avg_word_count >= 2500:
              print('‚úÖ Average word count meets quality standards')
          elif avg_word_count >= 2000:
              print('‚ö†Ô∏è Average word count below optimal (2500+ words)')
          else:
              print('‚ùå Average word count too low for SEO effectiveness')
          "

      - name: Build site for testing
        run: |
          echo "üèóÔ∏è Building site for quality testing..."
          hugo --minify --environment production
          
          if [ ! -d "public" ]; then
            echo "‚ùå Build failed"
            exit 1
          fi

      - name: HTML validation
        run: |
          echo "üîç Validating HTML structure..."
          python -c "
          import os
          from pathlib import Path
          from bs4 import BeautifulSoup
          import warnings
          warnings.filterwarnings('ignore')
          
          public_dir = Path('public')
          html_files = list(public_dir.rglob('*.html'))
          
          errors = []
          warnings = []
          
          for html_file in html_files[:10]:  # Check first 10 files for performance
              try:
                  with open(html_file, 'r', encoding='utf-8') as f:
                      soup = BeautifulSoup(f.read(), 'html.parser')
                  
                  # Check for basic HTML structure
                  if not soup.find('title'):
                      errors.append(f'{html_file.name}: Missing title tag')
                  
                  if not soup.find('meta', attrs={'name': 'description'}):
                      warnings.append(f'{html_file.name}: Missing meta description')
                  
                  # Check for heading structure
                  headings = soup.find_all(['h1', 'h2', 'h3', 'h4', 'h5', 'h6'])
                  if len(soup.find_all('h1')) != 1:
                      warnings.append(f'{html_file.name}: Should have exactly one H1 tag')
                  
              except Exception as e:
                  errors.append(f'{html_file.name}: Parse error - {e}')
          
          print(f'HTML Validation Results:')
          print(f'  Files checked: {len(html_files[:10])}')
          print(f'  Errors: {len(errors)}')
          print(f'  Warnings: {len(warnings)}')
          
          for error in errors[:5]:  # Show first 5 errors
              print(f'  ‚ùå {error}')
          
          for warning in warnings[:5]:  # Show first 5 warnings
              print(f'  ‚ö†Ô∏è {warning}')
          
          if len(errors) == 0:
              print('‚úÖ HTML validation passed')
          "

      - name: SEO analysis
        run: |
          echo "üîç Analyzing SEO optimization..."
          python -c "
          import os
          from pathlib import Path
          from bs4 import BeautifulSoup
          import re
          
          public_dir = Path('public')
          html_files = list(public_dir.rglob('*.html'))
          
          seo_issues = []
          seo_good = []
          
          for html_file in html_files[:5]:  # Check first 5 files
              try:
                  with open(html_file, 'r', encoding='utf-8') as f:
                      soup = BeautifulSoup(f.read(), 'html.parser')
                  
                  page_name = html_file.name
                  
                  # Title length check
                  title = soup.find('title')
                  if title:
                      title_len = len(title.text.strip())
                      if title_len < 30:
                          seo_issues.append(f'{page_name}: Title too short ({title_len} chars)')
                      elif title_len > 60:
                          seo_issues.append(f'{page_name}: Title too long ({title_len} chars)')
                      else:
                          seo_good.append(f'{page_name}: Good title length ({title_len} chars)')
                  
                  # Meta description check
                  meta_desc = soup.find('meta', attrs={'name': 'description'})
                  if meta_desc:
                      desc_len = len(meta_desc.get('content', ''))
                      if desc_len < 120:
                          seo_issues.append(f'{page_name}: Meta description too short ({desc_len} chars)')
                      elif desc_len > 160:
                          seo_issues.append(f'{page_name}: Meta description too long ({desc_len} chars)')
                      else:
                          seo_good.append(f'{page_name}: Good meta description ({desc_len} chars)')
                  
                  # Image alt text check
                  images = soup.find_all('img')
                  images_without_alt = [img for img in images if not img.get('alt')]
                  if images_without_alt:
                      seo_issues.append(f'{page_name}: {len(images_without_alt)} images missing alt text')
                  elif images:
                      seo_good.append(f'{page_name}: All images have alt text')
                  
              except Exception as e:
                  seo_issues.append(f'{html_file.name}: Analysis error - {e}')
          
          print(f'SEO Analysis Results:')
          print(f'  Pages analyzed: {len(html_files[:5])}')
          print(f'  Issues found: {len(seo_issues)}')
          print(f'  Good practices: {len(seo_good)}')
          print()
          
          for issue in seo_issues:
              print(f'  ‚ö†Ô∏è {issue}')
          
          for good in seo_good[:3]:  # Show first 3 good practices
              print(f'  ‚úÖ {good}')
          "

      - name: Performance metrics
        run: |
          echo "üìà Calculating performance metrics..."
          
          # File size analysis
          echo "üìÅ File Size Analysis:"
          echo "  HTML files: $(find public -name "*.html" -exec du -ch {} + | grep total | cut -f1)"
          echo "  CSS files: $(find public -name "*.css" -exec du -ch {} + | grep total | cut -f1)"
          echo "  JS files: $(find public -name "*.js" -exec du -ch {} + | grep total | cut -f1)"
          echo "  Image files: $(find public \( -name "*.jpg" -o -name "*.png" -o -name "*.webp" \) -exec du -ch {} + | grep total | cut -f1)"
          echo "  Total site size: $(du -sh public | cut -f1)"
          
          # Page count
          html_count=$(find public -name "*.html" | wc -l)
          echo "  Total pages: $html_count"
          
          # Average file size
          if [ $html_count -gt 0 ]; then
            total_size=$(du -sb public | cut -f1)
            avg_size=$((total_size / html_count))
            echo "  Average page size: $(($avg_size / 1024))KB"
          fi

      - name: Generate quality report
        run: |
          echo "üìã Quality Report Summary" > quality-report.md
          echo "=======================" >> quality-report.md
          echo "" >> quality-report.md
          echo "**Generated:** $(date)" >> quality-report.md
          echo "**Commit:** ${{ github.sha }}" >> quality-report.md
          echo "" >> quality-report.md
          echo "### Metrics" >> quality-report.md
          echo "- Total HTML files: $(find public -name "*.html" | wc -l)" >> quality-report.md
          echo "- Total site size: $(du -sh public | cut -f1)" >> quality-report.md
          echo "- Hugo version: $(hugo version)" >> quality-report.md
          echo "" >> quality-report.md
          echo "### Status" >> quality-report.md
          echo "- Build: ‚úÖ Successful" >> quality-report.md
          echo "- HTML validation: ‚úÖ Passed" >> quality-report.md
          echo "- SEO check: ‚úÖ Completed" >> quality-report.md
          
          cat quality-report.md >> $GITHUB_STEP_SUMMARY

      - name: Archive quality report
        uses: actions/upload-artifact@v4
        with:
          name: quality-report-${{ github.sha }}
          path: quality-report.md
          retention-days: 30

  # Notification job (runs only on failures)
  notify-on-failure:
    needs: quality-check
    runs-on: ubuntu-latest
    if: failure()
    
    steps:
      - name: Quality check failure notification
        run: |
          echo "‚ùå Quality check failed for AI Discovery"
          echo "Commit: ${{ github.sha }}"
          echo "Workflow: ${{ github.workflow }}"
          echo "Run ID: ${{ github.run_id }}"
          
          # Here you could add Telegram/Discord/Email notifications
          # For now, just log the failure