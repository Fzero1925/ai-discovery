#!/usr/bin/env python3
"""
Multi-Source System Comprehensive Test Suite
æµ‹è¯•å¤šæºçƒ­é—¨è¯é¢˜æ£€æµ‹ç³»ç»Ÿçš„å®Œæ•´åŠŸèƒ½
"""

import json
import sys
import os
import time
from datetime import datetime
from pathlib import Path

# æ·»åŠ æ¨¡å—è·¯å¾„
sys.path.append('.')
sys.path.append('modules')

def test_api_configurations():
    """æµ‹è¯•APIé…ç½®çŠ¶æ€"""
    print("ðŸ”§ Testing API Configurations...")
    
    configs = {
        'Reddit API': ['REDDIT_CLIENT_ID', 'REDDIT_CLIENT_SECRET', 'REDDIT_USER_AGENT'],
        'News API': ['NEWS_API_KEY'],
        'Product Hunt': ['PRODUCTHUNT_TOKEN'],
        'Telegram': ['TELEGRAM_BOT_TOKEN', 'TELEGRAM_CHAT_ID'],
        'Image APIs': ['UNSPLASH_ACCESS_KEY', 'PEXELS_API_KEY', 'PIXABAY_API_KEY']
    }
    
    results = {}
    for service, required_vars in configs.items():
        missing = [var for var in required_vars if not os.getenv(var)]
        if missing:
            results[service] = f"âŒ Missing: {', '.join(missing)}"
        else:
            results[service] = "âœ… Configured"
    
    print("API Configuration Status:")
    for service, status in results.items():
        print(f"  {service}: {status}")
    
    # è®¡ç®—é…ç½®å®Œæˆåº¦
    total_services = len(configs)
    configured_services = sum(1 for status in results.values() if "âœ…" in status)
    completion_rate = (configured_services / total_services) * 100
    
    print(f"\nðŸ“Š Configuration Completion: {completion_rate:.1f}% ({configured_services}/{total_services})")
    return results

def test_multi_source_detector():
    """æµ‹è¯•å¤šæºæ£€æµ‹å™¨"""
    print("\nðŸ” Testing Multi-Source Detector...")
    
    try:
        from trending_detector.multi_source_detector import MultiSourceTrendDetector
        
        detector = MultiSourceTrendDetector()
        print("âœ… Multi-source detector initialized successfully")
        
        # æµ‹è¯•å„ä¸ªæ•°æ®æº
        sources_to_test = [
            ('HackerNews', detector.detect_hackernews_trends, 5),
            ('RSS Feeds', detector.detect_rss_trends, 5),
        ]
        
        # åªæµ‹è¯•ä¸éœ€è¦APIçš„æ•°æ®æº
        results = {}
        for source_name, detection_func, limit in sources_to_test:
            try:
                print(f"  Testing {source_name}...")
                topics = detection_func(limit=limit)
                results[source_name] = {
                    'status': 'âœ… Working',
                    'topics_found': len(topics),
                    'sample_topics': [t.keyword for t in topics[:2]]
                }
                print(f"    Found {len(topics)} topics")
            except Exception as e:
                results[source_name] = {
                    'status': f'âŒ Error: {str(e)[:50]}...',
                    'topics_found': 0,
                    'sample_topics': []
                }
        
        # æµ‹è¯•Redditå’ŒNewså¦‚æžœæœ‰é…ç½®
        if os.getenv('REDDIT_CLIENT_ID'):
            try:
                print("  Testing Reddit API...")
                reddit_topics = detector.detect_reddit_trends(limit=3)
                results['Reddit'] = {
                    'status': 'âœ… Working',
                    'topics_found': len(reddit_topics),
                    'sample_topics': [t.keyword for t in reddit_topics[:2]]
                }
            except Exception as e:
                results['Reddit'] = {
                    'status': f'âŒ Error: {str(e)[:50]}...',
                    'topics_found': 0,
                    'sample_topics': []
                }
        
        if os.getenv('NEWS_API_KEY'):
            try:
                print("  Testing News API...")
                news_topics = detector.detect_news_trends(limit=3)
                results['News API'] = {
                    'status': 'âœ… Working',
                    'topics_found': len(news_topics),
                    'sample_topics': [t.keyword for t in news_topics[:2]]
                }
            except Exception as e:
                results['News API'] = {
                    'status': f'âŒ Error: {str(e)[:50]}...',
                    'topics_found': 0,
                    'sample_topics': []
                }
        
        print("Multi-Source Detection Results:")
        for source, result in results.items():
            print(f"  {source}: {result['status']}")
            if result['topics_found'] > 0:
                print(f"    Sample topics: {', '.join(result['sample_topics'])}")
        
        return results
        
    except ImportError as e:
        print(f"âŒ Failed to import multi-source detector: {e}")
        return {'error': 'Import failed'}
    except Exception as e:
        print(f"âŒ Unexpected error in multi-source detector: {e}")
        return {'error': f'Unexpected error: {e}'}

def test_keyword_generation():
    """æµ‹è¯•å…³é”®è¯ç”Ÿæˆ"""
    print("\nðŸ“Š Testing Keyword Generation...")
    
    try:
        # è¿è¡Œå…³é”®è¯ç”Ÿæˆè„šæœ¬
        import subprocess
        result = subprocess.run([sys.executable, 'scripts/multi_source_keywords.py'], 
                              capture_output=True, text=True, timeout=60)
        
        if result.returncode == 0:
            print("âœ… Multi-source keyword generation successful")
            
            # æ£€æŸ¥ç”Ÿæˆçš„æ–‡ä»¶
            if os.path.exists('daily_keywords.json'):
                with open('daily_keywords.json', 'r', encoding='utf-8') as f:
                    keywords_data = json.load(f)
                
                print(f"  Generated {len(keywords_data)} keywords")
                
                # æ˜¾ç¤ºç¤ºä¾‹å…³é”®è¯
                if keywords_data:
                    sample_keyword = keywords_data[0]
                    print(f"  Sample keyword: {sample_keyword.get('keyword', 'N/A')}")
                    print(f"  Trend score: {sample_keyword.get('trend_score', 0)}")
                    print(f"  Controversy score: {sample_keyword.get('controversy_score', 0)}")
                
                return {'status': 'success', 'keywords_count': len(keywords_data)}
            else:
                print("âš ï¸ Keywords file not generated")
                return {'status': 'warning', 'message': 'No keywords file'}
        else:
            print("âŒ Keyword generation failed")
            print(f"Error: {result.stderr}")
            return {'status': 'failed', 'error': result.stderr}
            
    except subprocess.TimeoutExpired:
        print("â° Keyword generation timed out")
        return {'status': 'timeout'}
    except Exception as e:
        print(f"âŒ Error in keyword generation: {e}")
        return {'status': 'error', 'message': str(e)}

def test_notification_system():
    """æµ‹è¯•é€šçŸ¥ç³»ç»Ÿ"""
    print("\nðŸ“¢ Testing Notification System...")
    
    if not os.getenv('TELEGRAM_BOT_TOKEN') or not os.getenv('TELEGRAM_CHAT_ID'):
        print("âš ï¸ Telegram credentials not configured, skipping notification test")
        return {'status': 'skipped', 'reason': 'No Telegram credentials'}
    
    try:
        from telegram_notify import send_telegram_message, format_test_message
        
        # å‘é€æµ‹è¯•æ¶ˆæ¯
        test_message = format_test_message()
        success = send_telegram_message(test_message)
        
        if success:
            print("âœ… Test notification sent successfully")
            return {'status': 'success'}
        else:
            print("âŒ Failed to send test notification")
            return {'status': 'failed'}
            
    except Exception as e:
        print(f"âŒ Error in notification system: {e}")
        return {'status': 'error', 'message': str(e)}

def test_enhanced_notification():
    """æµ‹è¯•å¢žå¼ºé€šçŸ¥åŠŸèƒ½"""
    print("\nðŸ§  Testing Enhanced Multi-Source Notification...")
    
    if not os.path.exists('notification_data.json'):
        print("âš ï¸ No notification data available, creating test data...")
        
        # åˆ›å»ºæµ‹è¯•æ•°æ®
        test_data = {
            "keyword_data": {
                "keyword": "Claude AI",
                "trend_score": 92,
                "controversy_score": 40,
                "monthly_revenue_estimate": "$318-880",
                "difficulty": "High",
                "commercial_intent": 0.88,
                "reason": "This keyword shows high competition with growing search trends. **TRENDING CONTROVERSY DETECTED** - Recent surge in problem-related queries, making this highly valuable for capturing user attention.",
                "data_sources": ["reddit_artificial", "news_api", "rss_techcrunch"],
                "related_queries": ["claude ai problems", "claude ai worse", "claude downgrade"],
                "sentiment": "negative",
                "is_trending_topic": True
            },
            "content_data": {
                "total_topics": 15,
                "total_keywords": 8,
                "controversy_detected": True,
                "sources_used": ["reddit_artificial", "news_api", "hackernews", "rss_techcrunch"],
                "avg_controversy_score": 25.5,
                "high_value_keywords": 3
            }
        }
        
        with open('notification_data.json', 'w', encoding='utf-8') as f:
            json.dump(test_data, f, indent=2, ensure_ascii=False)
    
    try:
        import subprocess
        result = subprocess.run([sys.executable, 'scripts/send_notification.py'], 
                              capture_output=True, text=True, timeout=30)
        
        if result.returncode == 0:
            print("âœ… Enhanced notification sent successfully")
            print("ðŸ“± Check your Telegram for the multi-source intelligence report")
            return {'status': 'success'}
        else:
            print("âŒ Enhanced notification failed")
            print(f"Error: {result.stderr}")
            return {'status': 'failed', 'error': result.stderr}
            
    except subprocess.TimeoutExpired:
        print("â° Notification timed out")
        return {'status': 'timeout'}
    except Exception as e:
        print(f"âŒ Error in enhanced notification: {e}")
        return {'status': 'error', 'message': str(e)}

def generate_test_report(api_results, detector_results, keyword_results, notification_results, enhanced_notification_results):
    """ç”Ÿæˆæµ‹è¯•æŠ¥å‘Š"""
    print("\n" + "="*60)
    print("ðŸ“‹ AI DISCOVERY MULTI-SOURCE SYSTEM TEST REPORT")
    print("="*60)
    
    # APIé…ç½®çŠ¶æ€
    configured_apis = sum(1 for status in api_results.values() if "âœ…" in status)
    total_apis = len(api_results)
    
    print(f"\nðŸ”§ API Configuration: {configured_apis}/{total_apis} configured")
    for service, status in api_results.items():
        priority = "ðŸŸ¢ Required" if service in ['Reddit API', 'News API'] else "ðŸŸ¡ Optional"
        print(f"  {service}: {status} ({priority})")
    
    # æ•°æ®æºæ£€æµ‹çŠ¶æ€
    working_sources = sum(1 for result in detector_results.values() 
                         if isinstance(result, dict) and "âœ…" in result.get('status', ''))
    total_sources = len([r for r in detector_results.values() if isinstance(r, dict)])
    
    print(f"\nðŸ” Data Source Detection: {working_sources}/{total_sources} working")
    for source, result in detector_results.items():
        if isinstance(result, dict):
            print(f"  {source}: {result['status']}")
    
    # ç³»ç»ŸåŠŸèƒ½çŠ¶æ€
    print(f"\nðŸ“Š System Functions:")
    print(f"  Keyword Generation: {keyword_results.get('status', 'unknown').title()}")
    print(f"  Basic Notification: {notification_results.get('status', 'unknown').title()}")
    print(f"  Enhanced Notification: {enhanced_notification_results.get('status', 'unknown').title()}")
    
    # æ•´ä½“è¯„ä¼°
    critical_components = [
        configured_apis >= 2,  # è‡³å°‘2ä¸ªAPIé…ç½®
        working_sources >= 2,   # è‡³å°‘2ä¸ªæ•°æ®æºå·¥ä½œ
        keyword_results.get('status') == 'success',
        enhanced_notification_results.get('status') in ['success', 'skipped']
    ]
    
    system_health = sum(critical_components) / len(critical_components) * 100
    
    print(f"\nðŸŽ¯ Overall System Health: {system_health:.1f}%")
    
    if system_health >= 80:
        status_emoji = "ðŸŸ¢"
        status_text = "EXCELLENT - System fully operational"
    elif system_health >= 60:
        status_emoji = "ðŸŸ¡"
        status_text = "GOOD - Minor issues detected"
    else:
        status_emoji = "ðŸ”´"
        status_text = "NEEDS ATTENTION - Critical issues found"
    
    print(f"{status_emoji} Status: {status_text}")
    
    # ä¸‹ä¸€æ­¥å»ºè®®
    print(f"\nðŸš€ Next Steps:")
    if configured_apis < total_apis:
        print("  1. Configure missing APIs (see API_SETUP.md)")
    if working_sources < 4:
        print("  2. Verify API credentials and internet connection")
    if keyword_results.get('status') != 'success':
        print("  3. Debug keyword generation system")
    if notification_results.get('status') != 'success':
        print("  4. Test Telegram notification setup")
    
    print(f"\nðŸ“– Documentation: API_SETUP.md")
    print(f"ðŸŒ Live Site: https://ai-discovery-nu.vercel.app/")
    print("="*60)

def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("ðŸš€ Starting AI Discovery Multi-Source System Test Suite...")
    print(f"ðŸ“… Test Time: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    
    # æ‰§è¡Œå„é¡¹æµ‹è¯•
    api_results = test_api_configurations()
    detector_results = test_multi_source_detector()
    keyword_results = test_keyword_generation()
    notification_results = test_notification_system()
    enhanced_notification_results = test_enhanced_notification()
    
    # ç”ŸæˆæŠ¥å‘Š
    generate_test_report(api_results, detector_results, keyword_results, 
                        notification_results, enhanced_notification_results)
    
    # æ¸…ç†æµ‹è¯•æ–‡ä»¶
    cleanup_files = ['daily_keywords.json', 'notification_data.json', 'multi_source_trends.json']
    for file in cleanup_files:
        if os.path.exists(file):
            os.remove(file)
    
    print(f"\nðŸ§¹ Cleanup completed")
    print(f"âœ… Test suite finished successfully")

if __name__ == "__main__":
    main()