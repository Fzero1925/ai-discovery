#!/usr/bin/env python3
"""
AI Discovery - Enhanced Content Generation with Hot Topics Support
ÊîØÊåÅÁÉ≠Èó®ËØùÈ¢òÂø´ÈÄüÂìçÂ∫îÂÜÖÂÆπÁîüÊàê
"""

import sys
import json
import os
from datetime import datetime
from pathlib import Path

# Add modules to path
sys.path.append('modules')

try:
    from content_generator.ai_tool_content_generator import AIToolContentGenerator
except ImportError as e:
    print(f"Error importing content generator: {e}")
    sys.exit(1)

def generate_trending_topic_content(generator, keyword_data, is_controversy=False):
    """
    ‰∏∫ÁÉ≠Èó®ËØùÈ¢òÁîüÊàê‰∏ìÈó®ÁöÑÂÜÖÂÆπ
    """
    tool_name = keyword_data['keyword']
    category = keyword_data.get('category', 'AI Tools')
    
    # Â¶ÇÊûúÊòØ‰∫âËÆÆËØùÈ¢òÔºå‰ΩøÁî®ÁâπÊÆäÁöÑÂÖ≥ÈîÆËØçÁªÑÂêà
    if is_controversy:
        target_keywords = [
            f"{tool_name} issues 2025",
            f"{tool_name} problems analysis", 
            f"what happened to {tool_name}",
            f"{tool_name} performance decline",
            f"{tool_name} alternatives comparison",
            f"is {tool_name} getting worse"
        ]
    else:
        target_keywords = [
            f"{tool_name} review",
            f"best {tool_name} guide", 
            f"{tool_name} complete analysis",
            f"how to use {tool_name}",
            f"{tool_name} vs alternatives"
        ]
    
    print(f"üéØ Generating content for: {tool_name} {'(CONTROVERSY)' if is_controversy else '(STANDARD)'}")
    return generator.generate_ai_tool_review(tool_name, target_keywords)

def main():
    print("üìù Generating AI tool content with hot topics support...")
    
    try:
        # Âä†ËΩΩÂÖ≥ÈîÆËØçÊï∞ÊçÆ
        if os.path.exists('daily_keywords.json'):
            with open('daily_keywords.json', 'r', encoding='utf-8') as f:
                keywords = json.load(f)
        else:
            print("‚ö†Ô∏è  No keywords file found, using default generation")
            keywords = []
        
        generator = AIToolContentGenerator()
        generated_files = []
        
        # ‰ºòÂÖàÂ§ÑÁêÜÁÉ≠Èó®‰∫âËÆÆËØùÈ¢ò
        controversy_keywords = [kw for kw in keywords if kw.get('is_trending_topic', False)]
        regular_keywords = [kw for kw in keywords if not kw.get('is_trending_topic', False)]
        
        print(f"üìä Found {len(controversy_keywords)} trending controversies, {len(regular_keywords)} regular topics")
        
        # Â§ÑÁêÜ‰∫âËÆÆËØùÈ¢òÔºà‰ºòÂÖàÁ∫ßÈ´òÔºâ
        for keyword_data in controversy_keywords[:2]:  # ÊúÄÂ§öÂ§ÑÁêÜ2‰∏™‰∫âËÆÆËØùÈ¢ò
            tool_name = keyword_data['keyword']
            try:
                content = generate_trending_topic_content(generator, keyword_data, is_controversy=True)
                
                # ÂàõÂª∫Êñá‰ª∂ÂêçÔºà‰∫âËÆÆËØùÈ¢òÊ†áËÆ∞Ôºâ
                filename = f"content/articles/{tool_name.lower().replace(' ', '-')}-controversy-analysis-{datetime.now().strftime('%Y-%m')}.md"
                
                # Á°Æ‰øùÁõÆÂΩïÂ≠òÂú®
                os.makedirs('content/articles', exist_ok=True)
                
                # Ê£ÄÊü•Êñá‰ª∂ÊòØÂê¶Â∑≤Â≠òÂú®
                if not os.path.exists(filename):
                    with open(filename, 'w', encoding='utf-8') as f:
                        f.write(content)
                    generated_files.append(filename)
                    print(f"‚úÖ Generated controversy analysis: {filename}")
                else:
                    print(f"‚ö†Ô∏è  File already exists: {filename}")
                    
            except Exception as e:
                print(f"‚ùå Error generating controversy content for {tool_name}: {e}")
        
        # Â§ÑÁêÜÂ∏∏ËßÑÂ∑•ÂÖ∑ËØÑÊµã
        for tool_name in list(generator.ai_tool_database.keys())[:3]:  # ÈôêÂà∂ÁîüÊàêÊï∞Èáè
            keyword_data = next((kw for kw in regular_keywords if tool_name.lower() in kw['keyword'].lower()), None)
            
            try:
                if keyword_data:
                    content = generate_trending_topic_content(generator, keyword_data, is_controversy=False)
                else:
                    # ‰ΩøÁî®ÈªòËÆ§ÂÖ≥ÈîÆËØç
                    target_keywords = [f"{tool_name} review", "AI tools 2025", f"best {tool_name} alternative"]
                    content = generator.generate_ai_tool_review(tool_name, target_keywords)
                
                # ÂàõÂª∫Êñá‰ª∂Âêç
                filename = f"content/reviews/{tool_name.lower().replace(' ', '-')}-review-{datetime.now().strftime('%Y-%m')}.md"
                
                # Á°Æ‰øùÁõÆÂΩïÂ≠òÂú®
                os.makedirs('content/reviews', exist_ok=True)
                
                # Ê£ÄÊü•Êñá‰ª∂ÊòØÂê¶Â∑≤Â≠òÂú®
                if not os.path.exists(filename):
                    with open(filename, 'w', encoding='utf-8') as f:
                        f.write(content)
                    generated_files.append(filename)
                    print(f"‚úÖ Generated review: {filename}")
                else:
                    print(f"‚ö†Ô∏è  File already exists: {filename}")
                    
            except Exception as e:
                print(f"‚ùå Error generating content for {tool_name}: {e}")
        
        print(f"üìà Generated {len(generated_files)} new articles")
        
        # ‰øùÂ≠òÁîüÊàêÁöÑÊñá‰ª∂ÂàóË°®
        with open('generated_files.txt', 'w', encoding='utf-8') as f:
            f.write('\n'.join(generated_files))
        
        # ‰∏∫ÈÄöÁü•ÂáÜÂ§áÊï∞ÊçÆ
        if keywords and len(generated_files) > 0:
            # ÈÄâÊã©ÊúÄÈ´ò‰ºòÂÖàÁ∫ßÁöÑÂÖ≥ÈîÆËØçÔºà‰∫âËÆÆËØùÈ¢ò‰ºòÂÖàÔºâ
            primary_keyword = controversy_keywords[0] if controversy_keywords else keywords[0]
            
            notification_data = {
                'keyword_data': primary_keyword,
                'content_data': {
                    'tool_name': primary_keyword['keyword'],
                    'title': f"{primary_keyword['keyword']} Complete Analysis Guide 2025",
                    'word_count': 2800,
                    'articles_generated': len(generated_files),
                    'categories_covered': list(set([kw.get('category', 'AI Tools') for kw in keywords[:3]])),
                    'total_keywords_analyzed': len(keywords),
                    'controversy_articles': len(controversy_keywords),
                    'trending_topics_detected': len([kw for kw in keywords if kw.get('controversy_score', 0) > 0])
                }
            }
            
            with open('notification_data.json', 'w', encoding='utf-8') as f:
                json.dump(notification_data, f, ensure_ascii=False, indent=2)
            
            print(f"üìä Notification data prepared - Primary keyword: {primary_keyword['keyword']}")
            if controversy_keywords:
                print(f"üî• Hot topic detected: {primary_keyword['keyword']} (Controversy score: {primary_keyword.get('controversy_score', 0)})")
    
    except Exception as e:
        print(f"‚ùå Critical error: {e}")
        sys.exit(1)

if __name__ == "__main__":
    main()