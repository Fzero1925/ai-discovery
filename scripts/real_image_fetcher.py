#!/usr/bin/env python3
"""
çœŸå®å›¾ç‰‡è·å–ç³»ç»Ÿ
ä½¿ç”¨Unsplash APIä¸ºAIå·¥å…·è·å–ç›¸å…³çš„çœŸå®å›¾ç‰‡
"""

import os
import sys
import requests
import json
import time
import hashlib
import codecs
from pathlib import Path
from PIL import Image
from urllib.parse import urlparse
from typing import Dict, List, Optional

# è§£å†³Windowsç¼–ç é—®é¢˜
if sys.platform == "win32":
    sys.stdout = codecs.getwriter("utf-8")(sys.stdout.detach())

class RealImageFetcher:
    """çœŸå®å›¾ç‰‡è·å–å™¨"""
    
    def __init__(self):
        self.access_key = os.getenv('UNSPLASH_ACCESS_KEY')
        self.images_dir = Path("static/images/tools")
        self.cache_dir = Path("static/images/cache")
        
        # åˆ›å»ºç›®å½•
        self.images_dir.mkdir(parents=True, exist_ok=True)
        self.cache_dir.mkdir(parents=True, exist_ok=True)
        
        # APIé…ç½®
        self.api_base = "https://api.unsplash.com"
        self.headers = {
            'Authorization': f'Client-ID {self.access_key}',
            'Accept-Version': 'v1'
        }
        
        # å›¾ç‰‡å°ºå¯¸é…ç½®
        self.image_sizes = {
            'featured': (1200, 630),    # OG image size
            'thumbnail': (400, 300),    # Card thumbnail
            'icon': (150, 150)          # Small icon
        }
        
        # AIå·¥å…·æœç´¢æŸ¥è¯¢ä¼˜åŒ–
        self.search_queries = {
            'ChatGPT': 'chatgpt ai assistant artificial intelligence',
            'Claude': 'claude ai anthropic artificial intelligence assistant',
            'Jasper AI': 'jasper ai writing content creation copywriting',
            'Copy.ai': 'copywriting ai content creation marketing tools',
            'Midjourney': 'midjourney ai art generation digital art',
            'DALL-E 3': 'dalle ai image generation artificial intelligence art',
            'Stable Diffusion': 'stable diffusion ai art generation machine learning',
            'Adobe Firefly': 'adobe firefly ai creative generative design',
            'GitHub Copilot': 'github copilot ai programming coding assistant',
            'Codeium': 'codeium ai coding assistant programming development',
            'Amazon CodeWhisperer': 'aws codewhisperer ai programming development',
            'TabNine': 'tabnine ai code completion programming assistant',
            'Grammarly': 'grammarly writing assistant ai proofreading',
            'Notion AI': 'notion ai productivity workspace collaboration',
            'Zapier': 'zapier automation workflow integration productivity',
            'Tableau': 'tableau data visualization analytics business intelligence',
            'DataRobot': 'datarobot machine learning ai analytics platform',
            'Power BI': 'power bi microsoft business intelligence analytics'
        }
        
        # è¯·æ±‚é—´éš”ï¼ˆé¿å…APIé™åˆ¶ï¼‰
        self.request_delay = 2  # 2ç§’é—´éš”
        
        # ç»Ÿè®¡
        self.stats = {
            'processed': 0,
            'downloaded': 0,
            'cached': 0,
            'errors': 0
        }
    
    def check_api_key(self) -> bool:
        """æ£€æŸ¥APIå¯†é’¥æ˜¯å¦æœ‰æ•ˆ"""
        if not self.access_key:
            print("âŒ é”™è¯¯ï¼šæœªæ‰¾åˆ°UNSPLASH_ACCESS_KEYç¯å¢ƒå˜é‡")
            print("è¯·å…ˆè¿è¡Œ: python scripts/test_unsplash_api.py")
            return False
        return True
    
    def search_images(self, query: str, count: int = 5) -> List[Dict]:
        """æœç´¢ç›¸å…³å›¾ç‰‡"""
        try:
            url = f"{self.api_base}/search/photos"
            params = {
                'query': query,
                'per_page': count,
                'orientation': 'landscape',
                'order_by': 'relevant'
            }
            
            response = requests.get(url, headers=self.headers, params=params, timeout=15)
            
            if response.status_code == 200:
                data = response.json()
                return data.get('results', [])
            elif response.status_code == 403:
                print(f"âš ï¸ APIé™åˆ¶ï¼šè¯·ç­‰å¾…åé‡è¯•")
                return []
            else:
                print(f"âš ï¸ æœç´¢å¤±è´¥: {response.status_code}")
                return []
                
        except Exception as e:
            print(f"âŒ æœç´¢é”™è¯¯: {e}")
            return []
    
    def download_image(self, image_url: str, tool_name: str, size_type: str) -> Optional[Path]:
        """ä¸‹è½½å¹¶å¤„ç†å›¾ç‰‡"""
        try:
            # ç”Ÿæˆç¼“å­˜æ–‡ä»¶å
            url_hash = hashlib.md5(image_url.encode()).hexdigest()[:8]
            safe_name = tool_name.lower().replace(' ', '-').replace('.', '')
            cache_filename = f"{safe_name}-{size_type}-{url_hash}.jpg"
            cache_path = self.cache_dir / cache_filename
            
            # æ£€æŸ¥ç¼“å­˜
            if cache_path.exists():
                print(f"  ğŸ“¦ ä½¿ç”¨ç¼“å­˜: {cache_filename}")
                self.stats['cached'] += 1
                return cache_path
            
            # ä¸‹è½½å›¾ç‰‡
            print(f"  ğŸ“¥ ä¸‹è½½å›¾ç‰‡: {image_url}")
            response = requests.get(image_url, timeout=30, stream=True)
            
            if response.status_code == 200:
                # ä¿å­˜åŸå§‹å›¾ç‰‡åˆ°ç¼“å­˜
                with open(cache_path, 'wb') as f:
                    for chunk in response.iter_content(chunk_size=8192):
                        f.write(chunk)
                
                # ä½¿ç”¨PILå¤„ç†å›¾ç‰‡
                with Image.open(cache_path) as img:
                    # è½¬æ¢ä¸ºRGB (ç§»é™¤é€æ˜é€šé“)
                    if img.mode in ('RGBA', 'LA', 'P'):
                        bg = Image.new('RGB', img.size, 'white')
                        if img.mode == 'P':
                            img = img.convert('RGBA')
                        bg.paste(img, mask=img.split()[-1] if img.mode == 'RGBA' else None)
                        img = bg
                    
                    # è°ƒæ•´å°ºå¯¸
                    target_size = self.image_sizes[size_type]
                    img = img.resize(target_size, Image.LANCZOS)
                    
                    # ä¿å­˜å¤„ç†åçš„å›¾ç‰‡
                    final_filename = f"{safe_name}-{size_type}.jpg"
                    final_path = self.images_dir / final_filename
                    img.save(final_path, 'JPEG', quality=90, optimize=True)
                    
                    print(f"  âœ… ä¿å­˜æˆåŠŸ: {final_filename}")
                    self.stats['downloaded'] += 1
                    return final_path
            
            else:
                print(f"  âŒ ä¸‹è½½å¤±è´¥: {response.status_code}")
                return None
                
        except Exception as e:
            print(f"  âŒ å¤„ç†å¤±è´¥: {e}")
            return None
    
    def process_tool_images(self, tool_name: str) -> bool:
        """å¤„ç†å•ä¸ªå·¥å…·çš„å›¾ç‰‡"""
        try:
            print(f"\\nğŸ” å¤„ç†å·¥å…·: {tool_name}")
            
            # è·å–æœç´¢æŸ¥è¯¢
            query = self.search_queries.get(tool_name, f"{tool_name} artificial intelligence")
            print(f"  ğŸ” æœç´¢æŸ¥è¯¢: {query}")
            
            # æœç´¢å›¾ç‰‡
            images = self.search_images(query, count=3)
            
            if not images:
                print(f"  âš ï¸ æœªæ‰¾åˆ°ç›¸å…³å›¾ç‰‡")
                return False
            
            print(f"  ğŸ“¸ æ‰¾åˆ° {len(images)} å¼ å€™é€‰å›¾ç‰‡")
            
            # å¤„ç†ä¸åŒå°ºå¯¸çš„å›¾ç‰‡
            success_count = 0
            
            for size_type in self.image_sizes.keys():
                # é€‰æ‹©æœ€ä½³å›¾ç‰‡
                best_image = None
                for img in images:
                    # ä¼˜å…ˆé€‰æ‹©é«˜åˆ†è¾¨ç‡ã€æ¨ªå‘çš„å›¾ç‰‡
                    if img['width'] >= self.image_sizes[size_type][0] and img['height'] >= self.image_sizes[size_type][1]:
                        best_image = img
                        break
                
                if not best_image and images:
                    best_image = images[0]  # ä½¿ç”¨ç¬¬ä¸€å¼ ä½œä¸ºå¤‡é€‰
                
                if best_image:
                    image_url = best_image['urls']['regular']
                    result_path = self.download_image(image_url, tool_name, size_type)
                    
                    if result_path:
                        success_count += 1
                        
                        # åˆ›å»ºplaceholderç‰ˆæœ¬ï¼ˆä¿æŒå‘åå…¼å®¹ï¼‰
                        if size_type == 'featured':
                            safe_name = tool_name.lower().replace(' ', '-').replace('.', '')
                            placeholder_path = self.images_dir / f"{safe_name}-placeholder.jpg"
                            if result_path != placeholder_path:
                                # å¤åˆ¶ä¸ºplaceholderæ–‡ä»¶
                                with open(result_path, 'rb') as src, open(placeholder_path, 'wb') as dst:
                                    dst.write(src.read())
                    
                    # æ·»åŠ å»¶è¿Ÿé¿å…APIé™åˆ¶
                    time.sleep(self.request_delay)
            
            if success_count > 0:
                print(f"  ğŸ‰ æˆåŠŸè·å– {success_count}/{len(self.image_sizes)} ä¸ªå°ºå¯¸çš„å›¾ç‰‡")
                return True
            else:
                print(f"  âŒ æ‰€æœ‰å›¾ç‰‡å¤„ç†å¤±è´¥")
                return False
                
        except Exception as e:
            print(f"  âŒ å¤„ç†å·¥å…·å¤±è´¥: {e}")
            return False
    
    def process_all_tools(self):
        """æ‰¹é‡å¤„ç†æ‰€æœ‰å·¥å…·çš„å›¾ç‰‡"""
        print("ğŸ¨ å¼€å§‹è·å–çœŸå®AIå·¥å…·å›¾ç‰‡...")
        print("=" * 50)
        
        if not self.check_api_key():
            return
        
        tools = list(self.search_queries.keys())
        total_tools = len(tools)
        
        print(f"ğŸ“Š å°†å¤„ç† {total_tools} ä¸ªAIå·¥å…·")
        
        for i, tool_name in enumerate(tools, 1):
            print(f"\\n[{i}/{total_tools}] å¤„ç†: {tool_name}")
            
            success = self.process_tool_images(tool_name)
            
            if success:
                self.stats['processed'] += 1
            else:
                self.stats['errors'] += 1
            
            # æ¯5ä¸ªå·¥å…·æ˜¾ç¤ºä¸€æ¬¡è¿›åº¦
            if i % 5 == 0:
                print(f"\\nğŸ“ˆ è¿›åº¦æŠ¥å‘Š: å·²å¤„ç† {i}/{total_tools} ä¸ªå·¥å…·")
                print(f"   âœ… æˆåŠŸ: {self.stats['processed']}")
                print(f"   ğŸ“¥ ä¸‹è½½: {self.stats['downloaded']}")
                print(f"   ğŸ“¦ ç¼“å­˜: {self.stats['cached']}")
                print(f"   âŒ é”™è¯¯: {self.stats['errors']}")
        
        # æœ€ç»ˆç»Ÿè®¡
        print(f"\\nğŸ‰ å›¾ç‰‡è·å–å®Œæˆ!")
        print("=" * 50)
        print(f"ğŸ“Š æœ€ç»ˆç»Ÿè®¡:")
        print(f"   ğŸ¯ å¤„ç†å·¥å…·: {self.stats['processed']}/{total_tools}")
        print(f"   ğŸ“¸ ä¸‹è½½å›¾ç‰‡: {self.stats['downloaded']}")
        print(f"   ğŸ“¦ ä½¿ç”¨ç¼“å­˜: {self.stats['cached']}")
        print(f"   âŒ å¤„ç†é”™è¯¯: {self.stats['errors']}")
        print(f"   ğŸ“ˆ æˆåŠŸç‡: {self.stats['processed']/max(1,total_tools)*100:.1f}%")

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸŒŸ AI Discovery çœŸå®å›¾ç‰‡è·å–ç³»ç»Ÿ")
    print("=" * 50)
    
    fetcher = RealImageFetcher()
    fetcher.process_all_tools()

if __name__ == "__main__":
    main()