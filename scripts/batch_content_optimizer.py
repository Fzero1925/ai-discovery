#!/usr/bin/env python3
"""
AI Discoveryæ‰¹é‡å†…å®¹ä¼˜åŒ–å™¨

ä½¿ç”¨å‡çº§åçš„å†…å®¹è´¨é‡ç”Ÿæˆç³»ç»Ÿé‡å†™ç°æœ‰æ–‡ç« ï¼Œç¡®ä¿ï¼š
- é«˜è´¨é‡ã€äººæ€§åŒ–çš„å†…å®¹
- åAIæ£€æµ‹æŠ€æœ¯
- SEOä¼˜åŒ–
- çœŸå®å›¾ç‰‡é›†æˆ
"""

import os
import sys
import re
import codecs
from pathlib import Path
from datetime import datetime
import frontmatter

# è§£å†³Windowsç¼–ç é—®é¢˜
if sys.platform == "win32":
    sys.stdout = codecs.getwriter("utf-8")(sys.stdout.detach())

# æ·»åŠ æ¨¡å—è·¯å¾„
sys.path.append(str(Path(__file__).parent.parent))
from modules.content_generator.ai_tool_content_generator import AIToolContentGenerator


class BatchContentOptimizer:
    """æ‰¹é‡å†…å®¹ä¼˜åŒ–å™¨"""
    
    def __init__(self, content_dir: str = "content/reviews"):
        self.content_dir = Path(content_dir)
        self.generator = AIToolContentGenerator()
        
        # ç»Ÿè®¡æ•°æ®
        self.stats = {
            'processed': 0,
            'optimized': 0,
            'skipped': 0,
            'errors': 0
        }
    
    def extract_tool_info_from_article(self, article_path: Path) -> dict:
        """ä»ç°æœ‰æ–‡ç« ä¸­æå–å·¥å…·ä¿¡æ¯"""
        try:
            with open(article_path, 'r', encoding='utf-8') as f:
                post = frontmatter.load(f)
            
            # ä»frontmatteræå–ä¿¡æ¯
            title = post.metadata.get('title', '')
            categories = post.metadata.get('categories', [])
            tags = post.metadata.get('tags', [])
            
            # å°è¯•ä»æ ‡é¢˜å’Œæ ‡ç­¾ä¸­æå–å·¥å…·åç§°
            tool_name = None
            
            # å¸¸è§çš„å·¥å…·åç§°åŒ¹é…
            common_tools = [
                'ChatGPT', 'Claude', 'Midjourney', 'DALL-E 3', 'Stable Diffusion',
                'GitHub Copilot', 'Codeium', 'Amazon CodeWhisperer', 'Grammarly',
                'Jasper AI', 'Copy.ai', 'Notion AI', 'Zapier', 'Tableau', 
                'DataRobot', 'TabNine', 'Adobe Firefly'
            ]
            
            # ä»æ ‡ç­¾ä¸­æŸ¥æ‰¾å·¥å…·åç§°
            for tag in tags:
                if tag in common_tools:
                    tool_name = tag
                    break
            
            # ä»æ ‡é¢˜ä¸­æå–å·¥å…·åç§°
            if not tool_name:
                for tool in common_tools:
                    if tool.lower() in title.lower():
                        tool_name = tool
                        break
            
            # å¦‚æœè¿˜æ²¡æ‰¾åˆ°ï¼Œå°è¯•ä»æ ‡é¢˜ä¸­æå–ç¬¬ä¸€ä¸ªè¯
            if not tool_name:
                title_words = title.split()
                if title_words:
                    # ç§»é™¤å¸¸è§è¯æ±‡åçš„ç¬¬ä¸€ä¸ªè¯å¯èƒ½æ˜¯å·¥å…·å
                    common_words = ['complete', 'comprehensive', 'review', 'guide', 'vs', 'competitors']
                    for word in title_words:
                        clean_word = re.sub(r'[^a-zA-Z0-9]', '', word)
                        if clean_word and clean_word.lower() not in common_words and len(clean_word) > 2:
                            tool_name = clean_word.title()
                            break
            
            category = categories[0] if categories else 'content_creation'
            
            return {
                'tool_name': tool_name or 'AI Tool',
                'category': category,
                'original_title': title,
                'tags': tags,
                'file_path': article_path
            }
            
        except Exception as e:
            print(f"âŒ Error extracting info from {article_path}: {e}")
            return None
    
    def optimize_article(self, tool_info: dict) -> bool:
        """ä¼˜åŒ–å•ç¯‡æ–‡ç« """
        try:
            tool_name = tool_info['tool_name']
            category = tool_info['category'] 
            file_path = tool_info['file_path']
            
            print(f"ğŸ”„ ä¼˜åŒ–æ–‡ç« : {tool_name} ({category})")
            
            # ç”Ÿæˆå…³é”®è¯
            target_keywords = [
                f"{tool_name} review",
                f"AI {category.replace('_', ' ')} tools",
                f"best {tool_name} alternative",
                "artificial intelligence software",
                f"{tool_name} vs competitors"
            ]
            
            # ä½¿ç”¨å‡çº§åçš„å†…å®¹ç”Ÿæˆå™¨åˆ›å»ºæ–°å†…å®¹
            optimized_content = self.generator.generate_ai_tool_review(tool_name, target_keywords)
            
            # è¯»å–åŸæ–‡ä»¶çš„frontmatterä»¥ä¿æŒæŸäº›å…ƒæ•°æ®
            with open(file_path, 'r', encoding='utf-8') as f:
                post = frontmatter.load(f)
            
            # ä¿æŒåŸæœ‰çš„æ—¥æœŸå’ŒæŸäº›å…ƒæ•°æ®
            original_date = post.metadata.get('date')
            
            # è§£ææ–°å†…å®¹çš„frontmatter
            new_post = frontmatter.loads(optimized_content)
            
            # åˆå¹¶å…ƒæ•°æ®ï¼šä¿ç•™æŸäº›åŸæœ‰æ•°æ®ï¼Œä½¿ç”¨æ–°çš„ä¼˜åŒ–æ•°æ®
            new_post.metadata['date'] = original_date or new_post.metadata.get('date')
            
            # å†™å…¥ä¼˜åŒ–åçš„å†…å®¹
            with open(file_path, 'w', encoding='utf-8') as f:
                f.write(frontmatter.dumps(new_post))
            
            print(f"  âœ… å·²ä¼˜åŒ–: {file_path.name}")
            return True
            
        except Exception as e:
            print(f"  âŒ ä¼˜åŒ–å¤±è´¥: {tool_info.get('tool_name', 'Unknown')}, Error: {e}")
            return False
    
    def optimize_all_articles(self):
        """æ‰¹é‡ä¼˜åŒ–æ‰€æœ‰æ–‡ç« """
        print("ğŸš€ å¼€å§‹æ‰¹é‡ä¼˜åŒ–AI Discoveryæ–‡ç« ...")
        print(f"ğŸ“‚ æ‰«æç›®å½•: {self.content_dir}")
        
        if not self.content_dir.exists():
            print(f"âŒ å†…å®¹ç›®å½•ä¸å­˜åœ¨: {self.content_dir}")
            return
        
        # è·å–æ‰€æœ‰markdownæ–‡ä»¶
        md_files = [f for f in self.content_dir.glob('*.md') if f.name != '_index.md']
        total_files = len(md_files)
        
        print(f"ğŸ“Š å‘ç° {total_files} ç¯‡æ–‡ç« éœ€è¦ä¼˜åŒ–")
        
        for i, md_file in enumerate(md_files, 1):
            print(f"\n[{i}/{total_files}] å¤„ç†æ–‡ç« : {md_file.name}")
            
            # æå–å·¥å…·ä¿¡æ¯
            tool_info = self.extract_tool_info_from_article(md_file)
            
            if not tool_info:
                print(f"  âš ï¸ è·³è¿‡: æ— æ³•æå–å·¥å…·ä¿¡æ¯")
                self.stats['skipped'] += 1
                continue
            
            # ä¼˜åŒ–æ–‡ç« 
            success = self.optimize_article(tool_info)
            
            if success:
                self.stats['optimized'] += 1
            else:
                self.stats['errors'] += 1
            
            self.stats['processed'] += 1
            
            # æ¯å¤„ç†5ç¯‡æ–‡ç« æ˜¾ç¤ºè¿›åº¦
            if i % 5 == 0:
                print(f"\nğŸ“ˆ è¿›åº¦æŠ¥å‘Š: å·²å¤„ç† {i}/{total_files} ç¯‡æ–‡ç« ")
                print(f"   âœ… æˆåŠŸä¼˜åŒ–: {self.stats['optimized']}")
                print(f"   âŒ å‡ºç°é”™è¯¯: {self.stats['errors']}")
                print(f"   âš ï¸ è·³è¿‡æ–‡ç« : {self.stats['skipped']}")
        
        # æœ€ç»ˆç»Ÿè®¡
        print(f"\nğŸ‰ æ‰¹é‡ä¼˜åŒ–å®Œæˆ!")
        print("=" * 50)
        print(f"ğŸ“Š æœ€ç»ˆç»Ÿè®¡:")
        print(f"   ğŸ“ æ€»å¤„ç†æ•°: {self.stats['processed']}")
        print(f"   âœ… ä¼˜åŒ–æˆåŠŸ: {self.stats['optimized']}")
        print(f"   âŒ ä¼˜åŒ–å¤±è´¥: {self.stats['errors']}")
        print(f"   âš ï¸ è·³è¿‡æ–‡ç« : {self.stats['skipped']}")
        print(f"   ğŸ“ˆ æˆåŠŸç‡: {self.stats['optimized']/max(1,self.stats['processed'])*100:.1f}%")


def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ¤– AI Discovery æ‰¹é‡å†…å®¹ä¼˜åŒ–å™¨")
    print("=" * 50)
    
    optimizer = BatchContentOptimizer()
    optimizer.optimize_all_articles()


if __name__ == "__main__":
    main()