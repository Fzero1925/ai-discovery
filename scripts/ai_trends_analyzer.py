#!/usr/bin/env python3
"""
AIå·¥å…·è¶‹åŠ¿ç›‘æ§ä¸å…³é”®è¯åˆ†æç³»ç»Ÿ
ä¸“ä¸ºå˜ç°ä¼˜åŒ–è®¾è®¡ï¼Œè‡ªåŠ¨å‘ç°é«˜æ”¶ç›ŠAIå·¥å…·æœºä¼š
"""

import os
import sys
import json
import codecs
import requests
import time
from datetime import datetime, timedelta
from dataclasses import dataclass
from typing import List, Dict, Optional
import argparse

# è§£å†³Windowsç¼–ç é—®é¢˜
if sys.platform == "win32":
    sys.stdout = codecs.getwriter("utf-8")(sys.stdout.detach())

@dataclass
class AIToolTrend:
    """AIå·¥å…·è¶‹åŠ¿æ•°æ®ç»“æ„"""
    keyword: str
    category: str
    search_volume: int
    trend_score: float
    competition_score: float
    commercial_intent: float
    difficulty: str
    affiliate_potential: str
    monthly_revenue_estimate: str
    reason: str
    data_sources: List[str]
    last_updated: str

class AITrendsAnalyzer:
    """AIå·¥å…·è¶‹åŠ¿åˆ†æå™¨"""
    
    def __init__(self):
        self.serpapi_key = os.getenv('SERPAPI_KEY')
        self.openai_api_key = os.getenv('OPENAI_API_KEY')
        
        # AIå·¥å…·åˆ†ç±»æ˜ å°„
        self.ai_categories = {
            'content_creation': ['writing', 'content', 'copywriting', 'blog', 'article'],
            'image_generation': ['image', 'art', 'photo', 'design', 'visual', 'picture'],
            'code_assistance': ['code', 'programming', 'developer', 'coding', 'github'],
            'productivity': ['productivity', 'workflow', 'automation', 'task', 'organization'],
            'video_creation': ['video', 'animation', 'editing', 'movie', 'film'],
            'voice_ai': ['voice', 'speech', 'audio', 'sound', 'transcription'],
            'data_analysis': ['data', 'analytics', 'analysis', 'insights', 'dashboard']
        }
        
        # é«˜æ”¶ç›Šå…³é”®è¯ç§å­åº“
        self.seed_keywords = [
            # å†…å®¹åˆ›ä½œç±»
            'jasper ai review', 'copy.ai alternatives', 'chatgpt plus worth it', 
            'notion ai features', 'grammarly premium review', 'writesonic pricing',
            # å›¾åƒç”Ÿæˆç±»  
            'midjourney alternatives', 'leonardo ai review', 'stable diffusion guide',
            'dall-e 3 review', 'adobe firefly pricing', 'canva ai features',
            # ä»£ç è¾…åŠ©ç±»
            'github copilot review', 'cursor ai pricing', 'tabnine alternatives',
            'codewhisperer vs copilot', 'replit ai review', 'codex openai',
            # ç”Ÿäº§åŠ›å·¥å…·ç±»
            'notion ai pricing', 'zapier alternatives', 'monday.com ai',
            'asana ai features', 'trello ai review', 'clickup ai',
            # æ–°å…´AIå·¥å…·
            'claude ai review', 'perplexity ai pricing', 'character ai alternatives',
            'runway ml review', 'luma ai pricing', 'synthesia alternatives'
        ]

    def analyze_trending_ai_tools(self, limit: int = 10) -> List[AIToolTrend]:
        """åˆ†æå½“å‰è¶‹åŠ¿AIå·¥å…·"""
        print("ğŸ” å¼€å§‹åˆ†æAIå·¥å…·å¸‚åœºè¶‹åŠ¿...")
        
        trending_tools = []
        
        # 1. åŸºäºç§å­å…³é”®è¯åˆ†æ
        for keyword in self.seed_keywords[:limit*2]:  # è·å–æ›´å¤šæ•°æ®ç”¨äºç­›é€‰
            try:
                tool_data = self._analyze_keyword(keyword)
                if tool_data and tool_data.commercial_intent > 0.7:  # åªä¿ç•™é«˜å•†ä¸šä»·å€¼
                    trending_tools.append(tool_data)
                    print(f"âœ… åˆ†æå®Œæˆ: {keyword} (å•†ä¸šä»·å€¼: {tool_data.commercial_intent:.2f})")
                else:
                    print(f"âš ï¸ è·³è¿‡ä½ä»·å€¼å…³é”®è¯: {keyword}")
                
                # é¿å…APIé™æµ
                time.sleep(0.5)
                
            except Exception as e:
                print(f"âŒ åˆ†æå¤±è´¥ {keyword}: {e}")
                continue
        
        # 2. æŒ‰å•†ä¸šä»·å€¼æ’åº
        trending_tools.sort(key=lambda x: (x.commercial_intent * x.trend_score), reverse=True)
        
        # 3. è¿”å›æœ€æœ‰ä»·å€¼çš„å·¥å…·
        top_tools = trending_tools[:limit]
        
        print(f"ğŸ“Š å‘ç° {len(top_tools)} ä¸ªé«˜ä»·å€¼AIå·¥å…·æœºä¼š")
        return top_tools

    def _analyze_keyword(self, keyword: str) -> Optional[AIToolTrend]:
        """åˆ†æå•ä¸ªå…³é”®è¯"""
        try:
            # 1. ç¡®å®šåˆ†ç±»
            category = self._categorize_keyword(keyword)
            
            # 2. æ¨¡æ‹Ÿæœç´¢é‡åˆ†æï¼ˆå®é™…éƒ¨ç½²ä¸­ä¼šä½¿ç”¨çœŸå®APIï¼‰
            search_data = self._get_search_volume(keyword)
            
            # 3. ç«äº‰åˆ†æ
            competition_data = self._analyze_competition(keyword)
            
            # 4. å•†ä¸šä»·å€¼è¯„ä¼°
            commercial_analysis = self._assess_commercial_value(keyword, category)
            
            # 5. è”ç›Ÿè¥é”€æ½œåŠ›
            affiliate_potential = self._assess_affiliate_potential(keyword, category)
            
            # 6. æ”¶ç›Šé¢„æµ‹
            revenue_estimate = self._estimate_monthly_revenue(
                search_data['volume'], 
                commercial_analysis['intent'], 
                affiliate_potential
            )
            
            return AIToolTrend(
                keyword=keyword,
                category=category,
                search_volume=search_data['volume'],
                trend_score=search_data['trend'],
                competition_score=competition_data['score'],
                commercial_intent=commercial_analysis['intent'],
                difficulty=competition_data['difficulty'],
                affiliate_potential=affiliate_potential,
                monthly_revenue_estimate=revenue_estimate,
                reason=commercial_analysis['reason'],
                data_sources=['internal_analysis', 'market_research'],
                last_updated=datetime.now().isoformat()
            )
            
        except Exception as e:
            print(f"âŒ å…³é”®è¯åˆ†æé”™è¯¯ {keyword}: {e}")
            return None

    def _categorize_keyword(self, keyword: str) -> str:
        """AIå·¥å…·åˆ†ç±»è¯†åˆ«"""
        keyword_lower = keyword.lower()
        
        for category, terms in self.ai_categories.items():
            if any(term in keyword_lower for term in terms):
                return category
        
        # ç‰¹æ®Šè§„åˆ™è¯†åˆ«
        if any(term in keyword_lower for term in ['ai', 'artificial intelligence', 'machine learning']):
            if any(term in keyword_lower for term in ['write', 'content', 'blog', 'copy']):
                return 'content_creation'
            elif any(term in keyword_lower for term in ['image', 'picture', 'art', 'design']):
                return 'image_generation'
            elif any(term in keyword_lower for term in ['code', 'program', 'develop']):
                return 'code_assistance'
        
        return 'ai_tools'  # é»˜è®¤åˆ†ç±»

    def _get_search_volume(self, keyword: str) -> Dict:
        """è·å–æœç´¢é‡æ•°æ®ï¼ˆæ¨¡æ‹Ÿå®ç°ï¼‰"""
        # å®é™…éƒ¨ç½²ä¸­ä¼šè°ƒç”¨Google Keyword Planner APIæˆ–SEMrush API
        
        # åŸºäºå…³é”®è¯ç‰¹å¾çš„æ™ºèƒ½ä¼°ç®—
        base_volume = 5000
        
        # å“ç‰Œè¯é€šå¸¸æœç´¢é‡æ›´é«˜
        if any(brand in keyword.lower() for brand in ['chatgpt', 'midjourney', 'notion', 'github']):
            base_volume *= 3
            
        # "review" å’Œ "alternatives" å…³é”®è¯æœç´¢é‡è¾ƒé«˜
        if 'review' in keyword.lower():
            base_volume *= 2
        if 'alternatives' in keyword.lower():
            base_volume *= 1.8
            
        # "pricing" å…³é”®è¯è¡¨æ˜è´­ä¹°æ„å›¾
        if 'pricing' in keyword.lower() or 'price' in keyword.lower():
            base_volume *= 1.5
            
        # è®¡ç®—è¶‹åŠ¿åˆ†æ•°ï¼ˆåŸºäºå…³é”®è¯ç‰¹å¾ï¼‰
        trend_score = 0.75  # åŸºç¡€è¶‹åŠ¿åˆ†æ•°
        
        if any(term in keyword.lower() for term in ['2025', 'new', 'latest', 'best']):
            trend_score += 0.15
            
        if any(term in keyword.lower() for term in ['ai', 'artificial intelligence']):
            trend_score += 0.10  # AIå·¥å…·æ•´ä½“è¶‹åŠ¿å‘ä¸Š
            
        return {
            'volume': min(base_volume, 50000),  # é™åˆ¶æœ€å¤§å€¼
            'trend': min(trend_score, 1.0)
        }

    def _analyze_competition(self, keyword: str) -> Dict:
        """ç«äº‰åˆ†æ"""
        # åŸºäºå…³é”®è¯ç‰¹å¾çš„ç«äº‰åº¦åˆ†æ
        competition_score = 0.5  # åŸºç¡€ç«äº‰åº¦
        
        # å“ç‰Œè¯ç«äº‰åº¦é€šå¸¸æ›´é«˜
        brand_terms = ['chatgpt', 'midjourney', 'notion', 'github', 'openai', 'google']
        if any(brand in keyword.lower() for brand in brand_terms):
            competition_score += 0.2
            
        # "best" å’Œ "top" å…³é”®è¯ç«äº‰æ¿€çƒˆ
        if any(term in keyword.lower() for term in ['best', 'top', 'compare']):
            competition_score += 0.15
            
        # "review" ç«äº‰åº¦ä¸­ç­‰
        if 'review' in keyword.lower():
            competition_score += 0.05
            
        # "alternatives" ç«äº‰åº¦ç›¸å¯¹è¾ƒä½
        if 'alternatives' in keyword.lower():
            competition_score -= 0.1
            
        competition_score = max(0.1, min(competition_score, 0.9))
        
        # ç¡®å®šéš¾åº¦ç­‰çº§
        if competition_score < 0.4:
            difficulty = "Low"
        elif competition_score < 0.7:
            difficulty = "Medium"  
        else:
            difficulty = "High"
            
        return {
            'score': competition_score,
            'difficulty': difficulty
        }

    def _assess_commercial_value(self, keyword: str, category: str) -> Dict:
        """å•†ä¸šä»·å€¼è¯„ä¼°"""
        commercial_intent = 0.6  # åŸºç¡€å•†ä¸šæ„å›¾
        
        # é«˜å•†ä¸šæ„å›¾å…³é”®è¯
        high_intent_terms = ['review', 'pricing', 'cost', 'buy', 'purchase', 'worth it', 'alternatives', 'vs', 'compare']
        intent_boost = sum(0.1 for term in high_intent_terms if term in keyword.lower())
        commercial_intent += intent_boost
        
        # åˆ†ç±»è°ƒæ•´
        category_multipliers = {
            'content_creation': 0.95,  # å†…å®¹åˆ›ä½œå·¥å…·è½¬åŒ–ç‡é«˜
            'code_assistance': 0.90,   # å¼€å‘å·¥å…·Bç«¯ä»˜è´¹æ„æ„¿å¼º
            'image_generation': 0.92,  # è®¾è®¡å·¥å…·éœ€æ±‚æ—ºç››
            'productivity': 0.88,      # ç”Ÿäº§åŠ›å·¥å…·å¸‚åœºæˆç†Ÿ
            'video_creation': 0.85,    # è§†é¢‘å·¥å…·ä¸“ä¸šæ€§å¼º
            'voice_ai': 0.80,         # è¯­éŸ³AIå¸‚åœºæ–°å…´
            'data_analysis': 0.87      # æ•°æ®åˆ†æBç«¯éœ€æ±‚
        }
        
        commercial_intent *= category_multipliers.get(category, 0.75)
        commercial_intent = min(commercial_intent, 1.0)
        
        # ç”Ÿæˆæ¨èç†ç”±
        reasons = []
        if 'review' in keyword.lower():
            reasons.append("è¯„æµ‹ç±»å†…å®¹è½¬åŒ–ç‡é«˜")
        if 'alternatives' in keyword.lower():
            reasons.append("ç”¨æˆ·å¯»æ‰¾æ›¿ä»£æ–¹æ¡ˆï¼Œè´­ä¹°æ„å›¾æ˜ç¡®")
        if 'pricing' in keyword.lower():
            reasons.append("ä»·æ ¼ç›¸å…³æœç´¢è¡¨æ˜å¼ºçƒˆè´­ä¹°æ„å›¾")
        if commercial_intent > 0.85:
            reasons.append("AIå·¥å…·å¸‚åœºå¿«é€Ÿå¢é•¿")
            
        reason = " | ".join(reasons) if reasons else f"{category.replace('_', ' ').title()}å¸‚åœºéœ€æ±‚æ—ºç››"
        
        return {
            'intent': commercial_intent,
            'reason': reason
        }

    def _assess_affiliate_potential(self, keyword: str, category: str) -> str:
        """è”ç›Ÿè¥é”€æ½œåŠ›è¯„ä¼°"""
        
        # åŸºäºå·¥å…·ç±»å‹çš„è”ç›Ÿè¥é”€æœºä¼š
        high_affiliate_categories = ['content_creation', 'image_generation', 'productivity']
        medium_affiliate_categories = ['code_assistance', 'video_creation', 'data_analysis']
        
        # çŸ¥åå·¥å…·é€šå¸¸æœ‰è”ç›Ÿè®¡åˆ’
        known_tools = ['jasper', 'copy.ai', 'notion', 'grammarly', 'canva', 'zapier']
        has_known_tool = any(tool in keyword.lower() for tool in known_tools)
        
        if category in high_affiliate_categories and has_known_tool:
            return "Very High"
        elif category in high_affiliate_categories or has_known_tool:
            return "High"
        elif category in medium_affiliate_categories:
            return "Medium"
        else:
            return "Low"

    def _estimate_monthly_revenue(self, search_volume: int, commercial_intent: float, affiliate_potential: str) -> str:
        """æœˆæ”¶ç›Šé¢„ä¼°"""
        
        # åŸºç¡€æ”¶ç›Šè®¡ç®—
        base_revenue = (search_volume / 1000) * commercial_intent * 10
        
        # è”ç›Ÿè¥é”€æ½œåŠ›è°ƒæ•´
        affiliate_multipliers = {
            "Very High": 3.0,
            "High": 2.0,
            "Medium": 1.2,
            "Low": 0.8
        }
        
        base_revenue *= affiliate_multipliers.get(affiliate_potential, 1.0)
        
        # è®¡ç®—æ”¶ç›ŠåŒºé—´
        min_revenue = int(base_revenue * 0.6)
        max_revenue = int(base_revenue * 1.8)
        
        # ç¡®ä¿åˆç†èŒƒå›´
        min_revenue = max(min_revenue, 10)
        max_revenue = min(max_revenue, 500)
        
        return f"${min_revenue}-{max_revenue}"

    def save_trending_data(self, trends: List[AIToolTrend], filename: str = "data/trending_ai_tools_cache.json"):
        """ä¿å­˜è¶‹åŠ¿æ•°æ®"""
        os.makedirs(os.path.dirname(filename), exist_ok=True)
        
        # è½¬æ¢ä¸ºå¯åºåˆ—åŒ–æ ¼å¼
        trends_data = []
        for trend in trends:
            trends_data.append({
                'keyword': trend.keyword,
                'category': trend.category,
                'search_volume': trend.search_volume,
                'trend_score': trend.trend_score,
                'competition_score': trend.competition_score,
                'commercial_intent': trend.commercial_intent,
                'difficulty': trend.difficulty,
                'affiliate_potential': trend.affiliate_potential,
                'monthly_revenue_estimate': trend.monthly_revenue_estimate,
                'reason': trend.reason,
                'data_sources': trend.data_sources,
                'last_updated': trend.last_updated
            })
        
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(trends_data, f, indent=2, ensure_ascii=False)
        
        print(f"ğŸ’¾ å·²ä¿å­˜ {len(trends_data)} ä¸ªAIå·¥å…·è¶‹åŠ¿åˆ° {filename}")

    def generate_market_report(self, trends: List[AIToolTrend]) -> str:
        """ç”Ÿæˆå¸‚åœºåˆ†ææŠ¥å‘Š"""
        if not trends:
            return "æš‚æ— è¶‹åŠ¿æ•°æ®"
        
        # ç»Ÿè®¡åˆ†æ
        total_tools = len(trends)
        high_value_tools = len([t for t in trends if t.commercial_intent > 0.8])
        avg_search_volume = sum(t.search_volume for t in trends) // total_tools
        
        # åˆ†ç±»ç»Ÿè®¡
        category_stats = {}
        for trend in trends:
            cat = trend.category
            if cat not in category_stats:
                category_stats[cat] = {'count': 0, 'avg_revenue': 0}
            category_stats[cat]['count'] += 1
        
        # ç”ŸæˆæŠ¥å‘Š
        report = f"""
ğŸ“Š AIå·¥å…·å¸‚åœºè¶‹åŠ¿åˆ†ææŠ¥å‘Š
æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M')}

ğŸ¯ æ ¸å¿ƒæŒ‡æ ‡:
â€¢ åˆ†æå·¥å…·æ€»æ•°: {total_tools}ä¸ª
â€¢ é«˜ä»·å€¼å·¥å…·: {high_value_tools}ä¸ª ({high_value_tools/total_tools*100:.1f}%)
â€¢ å¹³å‡æœç´¢é‡: {avg_search_volume:,}/æœˆ
â€¢ é¢„ä¼°æ€»æ”¶ç›Šæ½œåŠ›: ${sum(int(t.monthly_revenue_estimate.replace('$', '').split('-')[1]) for t in trends if '-' in t.monthly_revenue_estimate)}+/æœˆ

ğŸ“ˆ åˆ†ç±»åˆ†å¸ƒ:
""" + "\n".join([f"â€¢ {cat.replace('_', ' ').title()}: {stats['count']}ä¸ªå·¥å…·" 
                for cat, stats in category_stats.items()]) + f"""

ğŸ’ é¡¶çº§æœºä¼š:
""" + "\n".join([f"â€¢ {trend.keyword} | æ”¶ç›Šé¢„ä¼°: {trend.monthly_revenue_estimate} | è”ç›Ÿæ½œåŠ›: {trend.affiliate_potential}"
                for trend in trends[:3]]) + """

ğŸš€ å»ºè®®è¡ŒåŠ¨:
1. ä¼˜å…ˆåˆ¶ä½œå‰3ä¸ªå·¥å…·çš„è¯¦ç»†è¯„æµ‹
2. é‡ç‚¹å…³æ³¨high_value_toolsä¸ªé«˜å•†ä¸šä»·å€¼å·¥å…·
3. å»ºç«‹é•¿æœŸè·Ÿè¸ªå’Œæ›´æ–°æœºåˆ¶
"""
        
        return report

def main():
    parser = argparse.ArgumentParser(description='AIå·¥å…·è¶‹åŠ¿åˆ†æç³»ç»Ÿ')
    parser.add_argument('--limit', type=int, default=10, help='åˆ†æå·¥å…·æ•°é‡é™åˆ¶')
    parser.add_argument('--save', action='store_true', help='ä¿å­˜åˆ†æç»“æœ')
    parser.add_argument('--report', action='store_true', help='ç”Ÿæˆå¸‚åœºæŠ¥å‘Š')
    parser.add_argument('--category', help='æŒ‡å®šåˆ†æçš„å·¥å…·åˆ†ç±»')
    
    args = parser.parse_args()
    
    print("ğŸš€ å¯åŠ¨AIå·¥å…·è¶‹åŠ¿åˆ†æç³»ç»Ÿ...")
    print(f"ğŸ¯ ç›®æ ‡: å‘ç° {args.limit} ä¸ªé«˜æ”¶ç›ŠAIå·¥å…·æœºä¼š")
    
    analyzer = AITrendsAnalyzer()
    
    try:
        # æ‰§è¡Œè¶‹åŠ¿åˆ†æ
        trending_tools = analyzer.analyze_trending_ai_tools(limit=args.limit)
        
        if not trending_tools:
            print("âŒ æœªå‘ç°ä»»ä½•è¶‹åŠ¿æ•°æ®")
            return False
        
        # ä¿å­˜ç»“æœ
        if args.save:
            analyzer.save_trending_data(trending_tools)
        
        # ç”ŸæˆæŠ¥å‘Š
        if args.report:
            report = analyzer.generate_market_report(trending_tools)
            print("\n" + "="*60)
            print(report)
            print("="*60)
            
            # ä¿å­˜æŠ¥å‘Š
            report_file = f"data/market_report_{datetime.now().strftime('%Y%m%d')}.txt"
            os.makedirs(os.path.dirname(report_file), exist_ok=True)
            with open(report_file, 'w', encoding='utf-8') as f:
                f.write(report)
            print(f"ğŸ“„ å¸‚åœºæŠ¥å‘Šå·²ä¿å­˜: {report_file}")
        
        # æ˜¾ç¤ºç»“æœæ‘˜è¦
        print(f"\nâœ… åˆ†æå®Œæˆ! å‘ç° {len(trending_tools)} ä¸ªé«˜ä»·å€¼AIå·¥å…·æœºä¼š")
        print("\nğŸ† Top 3 æ¨è:")
        for i, tool in enumerate(trending_tools[:3], 1):
            print(f"{i}. {tool.keyword}")
            print(f"   æ”¶ç›Šé¢„ä¼°: {tool.monthly_revenue_estimate}/æœˆ")
            print(f"   å•†ä¸šä»·å€¼: {tool.commercial_intent:.2f}")
            print(f"   è”ç›Ÿæ½œåŠ›: {tool.affiliate_potential}")
            print()
        
        return True
        
    except Exception as e:
        print(f"âŒ ç³»ç»Ÿé”™è¯¯: {e}")
        return False

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)